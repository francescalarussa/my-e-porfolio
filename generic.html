<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Modules| Larussa Francesca</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo"><strong>Francesca</strong> <span>Larussa</span></a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="landing.html">About me</a></li>
							<li><a href="generic.html">Modules</a></li>
							<li><a href="elements.html">Skills</a></li>
						</ul>
						<ul class="actions stacked">
							<li><a href="#" class="button primary fit">Get Started</a></li>
							<li><a href="#" class="button fit">Log In</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main" class="alt">

						<!-- One -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h1>Modules</h1>
									</header>
									<span class="image main"><img src="images/pic11.jpg" alt="" /></span>
									<p> This section brings together some of the work produced during the Units of the course "Deciphering Big Data"</p>
									<section class="box">
										<h2> Unit 1 - Introduction to Big Data Technologies and Data Management</h2>
										<p> During the first unit, I had the opportunity to explore the definition of big data and the methods and techniques for managing it, which were organized into four steps: cleansing, standardization, formatting, and normalization. I also reviewed the definitions of data formats, including structured, semi-structured, and unstructured data, and the definitions of CSV, JSON, and XML, which will be revisited in the following section. As an activity, I picked up the e-portfolio that I had already started and began organizing the main page and the “About Me” section. In addition, I participated in the collaborative discussion on “the data collection process.”</p>
										<h3>Collaborative Discussion - Initial Post</h3>
										<p> As mentioned above, during this Unit, I took part in a collaborative discussion on data collection process. The screenshot below represents my initial post/p>
										<span class="image fit">
											<img src="images/unit1.png" alt="Unit 1" style="max-width:100%; height:auto;">
										</span>
									</section>
								<section class="box">
										<h2> Unit 2 - Introduction to data Types and Formats</h2>
										<p> In this Unit, the focus was on tools to manage big data that are useful for managing, analyzing, and visualizing it. After reading Chapter 8 (8.29 - 8.35) of Sardar and Pandey's book titled "Big Data Computing”, I learned that typical analytical tools are used to manage, refine, discover, predict, and validate data. The most commonly used tools are NoSQL,Cassandra, Apache Hadoop and MapReduce, Apache Mahout, Storm, and Apache Spark. The choice of one tool over another is based on the specific needs. Considering the ones listed before, NoSQL is chosen for managing unstructured and non-relational data, Cassandra ensures replication and high availability, Hadoop and MapReduce can be chosen for distributed storage and batch processing, Mahout is used for scalable machine learning algorithms, Storm is used for real-time streaming data, and Spark allows fast in-memory processing. Delving into this aspect allowed me to participate in the team project meeting with in-deep knowledge of the topic and engage in the discussion on which server would be better for the implementation of the database. During this unit, I also continued my collaborative discussion on "The Data Collection Process," writing two peer reviews.</p>
										<h3> Collaborative Discussion - Peer Reviews</h3>
										<p> As mentioned above, during this Unit, I took part in a collaborative discussion on data collection process. The screenshot below represents my peer reviews</p>
										<span class="image fit">
											<img src="images/unit2peer.png" alt="Unit 1" style="max-width:100%; height:auto;">
											<img src="images/unit2peer2.png" alt="Unit 1" style="max-width:100%; height:auto;">
											</span>
									</section>
									<h2> Unit 3 - Data Collection and Storage</h2>
										<p> During Unit 3, I learned to use the pandas library for data cleaning and preparation.  Because the datasets contained missing values, poorly formatted strings, duplicates, outliers, and repeated categories, I was able to overcome these issues using pandas.For example, Pandas allows us to recognize the missing values and remove or modify them and transform data through commands such as Replace, rename, map, cut, and qcut , which were used when working with categorical data. In addition, the use of categorical data commands, such as group by and value_counts, is faster and uses less memory.In the book “Big Data Computing: Advances in Technologies, Methodologies and Applications”,  I learned that big data can be managed in two ways: batch processing and stream processing. Batch processing can be used to elaborate on largevolumes of data periodically, whereas stream processing is used for real-time analysis. Cloud providers offer tools for storage, processing, analytics, and data orchestration. The major advantages are scalability and advanced insights, while the disadvantages are data security, cost, and complexity. During this Unit, I concluded the collaborative discussion “The Data Collection Process," with a summary post, and I also did a web scraping exercise and posted it on the wiki module.</p>
										<h3> Collaborative Discussion - Summary Post</h3>
										<p> As mentioned above, during this Unit, I took part in a collaborative discussion on data collection process. The screenshot below represents my summary post</p>
										<span class="image fit">
											<img src="images/Unit3Sum.png" alt="Unit 1" style="max-width:100%; height:auto;">
										<h4>Web Scrapping exercise</h4>
										<p>
                                        Web Scraping

                                        In this activity, I created a Python script to extract and organize information from the Prospectus webpage discussing the Data Scientist role. The goal was to identify the key content of the professional profile. The data were then collected in a JSON file to allow easy and structured consultation for the content analysis.

										The script is as follows:
											<pre><code>
											from bs4 import BeautifulSoup
										    import requests
											import json
                                            url= "https://www.prospects.ac.uk/job-profiles/data-scientist"
                                            response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
											soup= BeautifulSoup(response.text, "html.parser")
											print("Title:", soup.find("h1").text)
											print("\n Data Scientist content:\n")
											results = soup.find_all(string=lambda text: "data scientist" in text.lower())
											for r in results[:10]:
											print("-", r.strip())
											with open("data_science.json", "w") as f:
											json.dump({"results":[r.strip() for r in results]}, f, indent=4)
											print("\nFile JSON correctly created”)
											</code></pre>

                                        The results can be found in the attached file.

										After completing this activity, I can affirm that using libraries such as “Requests” and “BeautifulSoup” allows for collecting the desired data efficiently. In addition, Web Scraping enables the isolation of key information without the need to read the entire webpage. This methodology can be extremely useful in other contexts, allowing systematic and automated data collection.</p>
											<a href="assets/data_science.json" download> Download JSON </a>
										</span>
									</section>

						
				
								</div>
							</section>

					</div>

				<!-- Contact -->
					<section id="contact">
						<div class="inner">
							<section>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<label for="name">Name</label>
											<input type="text" name="name" id="name" />
										</div>
										<div class="field half">
											<label for="email">Email</label>
											<input type="text" name="email" id="email" />
										</div>
										<div class="field">
											<label for="message">Message</label>
											<textarea name="message" id="message" rows="6"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send Message" class="primary" /></li>
										<li><input type="reset" value="Clear" /></li>
									</ul>
								</form>
							</section>
							<section class="split">
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-envelope"></span>
										<h3>Email</h3>
										<a href="#">larussafrancesca1@gmail.com</a>
									</div>
								</section>
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-phone"></span>
										<h3>Phone</h3>
										<span>(+39) 3664182661</span>
									</div>
								</section>
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-home"></span>
										<h3>Address</h3>
										<span> 
									    Turin (TO)<br />
										Italy</span>
									</div>
								</section>
							</section>
						</div>
					</section>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<ul class="icons">
								<li><a href="#" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
								<li><a href="#" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li>
								<li><a href="#" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
								<li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								<li><a href="#" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
							</ul>
							<ul class="copyright">
								<li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>

</html>














